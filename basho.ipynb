{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Haiku Generation Algorithm \n",
    "Based on the poetry of Basho \n",
    "By Thomas Wee \n",
    "version 1\n",
    "May 2020 \n",
    "\"\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import os \n",
    "import nltk \n",
    "import syllables \n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import string \n",
    "from collections import defaultdict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to  mount  fuji  then\n",
      "come  and  evening  someone\n",
      "near  my  pillow  pees\n"
     ]
    }
   ],
   "source": [
    "def walk_graph(graph, distance, start_node=None):\n",
    "    #returns word list from randomly weighted walk\n",
    "    if distance <= 0:\n",
    "        return []\n",
    "    if not start_node:\n",
    "        start_node = random.choice(list(graph.keys()))\n",
    "        \n",
    "     \n",
    "        \n",
    "    weights = np.array(\n",
    "    list(markov_graph[start_node].values()),\n",
    "    dtype=np.float64)\n",
    "    weights /= weights.sum()\n",
    "    \n",
    "    choices = list(markov_graph[start_node].keys())\n",
    "    chosen_word = np.random.choice(choices,None,p=weights)\n",
    "    #determine the syllables of the chosen word\n",
    "    syl = syllables.estimate(chosen_word)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #return word, recusively calling function, subtract based on number of syllables in chosen word\n",
    "    return [chosen_word] + walk_graph(graph, distance = distance-syl, start_node = chosen_word)\n",
    "\n",
    "\n",
    "words = (walk_graph(markov_graph, distance = 5))\n",
    "poem.append(words)\n",
    "print('  '.join(words))\n",
    "\n",
    "words = (walk_graph(markov_graph, distance = 7))\n",
    "poem.append(words)\n",
    "print('  '.join(words))\n",
    "\n",
    "\n",
    "words = (walk_graph(markov_graph, distance = 5))\n",
    "poem.append(words)\n",
    "print('  '.join(words))\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open file containing Basho poems\n",
    "with open('basho.txt', encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "  \n",
    "file.close()\n",
    "#separate text into words\n",
    "words = text.split()\n",
    "#remove punctuation \n",
    "table = str.maketrans('','',  string.punctuation)\n",
    "tokenized_text = [ \n",
    "    w.translate(table) \n",
    "    for w in words\n",
    "    if w != (' ', \"translated\",\"translation,\",\"â€“\")\n",
    "    \n",
    "    \n",
    "]\n",
    "  \n",
    "\n",
    "markov_graph = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "last_word = tokenized_text[0].lower()\n",
    "for word in tokenized_text[1:]:\n",
    "    word = word.lower()\n",
    "    markov_graph[last_word][word]+= 1\n",
    "    last_word = word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
